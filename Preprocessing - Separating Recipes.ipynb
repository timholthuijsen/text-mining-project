{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tEACH PORTION: 1 Apple\n",
      "\n",
      "1\tTEMPERATURE: 300° F. Oven\n",
      "\n",
      "2\tPierce top of apple holding paring knife at a 45 degree angle to stem. Rotate knife around top to produce small cone-shaped top. Set tops aside. Using melon baller or teaspoon, remove core from apples, being careful not to pierce the bottom of apples. \n",
      "\n",
      "3\tIn small bowl, stir together tahini, raisins, lemon juice, grated lemon peel, maple syrup, cinnamon and a pinch of ground cardamom (optional). Fill apple cavitites almost to top with raisin mixture. Replace apple tops. Set apples in baking tray, pour orange juice over apples and bake for 15 minutes or until apples are soft when pierced with toothpick.\n",
      "\n",
      "4\tSaute mushrooms in 2 tablespoons of the stock, adding more stock if necessary, or in 1 tablespoon oil in large pot over medium heat for 5 minutes or until they start to brown.\n",
      "\n",
      "5\tAdd remaining stock, green onions, marjoram, thyme, 1/4 teaspoon salt if desired, and pepper; simmer fro 10 minutes. Adjust seasoning. Divide broth among 4 serving bowls. Garnish with parsley.\n",
      "\n",
      "6\tEACH PORTION: 1 Patty\n",
      "\n",
      "7\tIn a one quart pot, bring 2 cups water to boil. Add rice and lentils; reduce heat and cook for 50 minutes. Remove from heat, transfer to bowl and mash with a spoon until rice and lentils bind together.\n",
      "\n",
      "8\tSaute diced onions and sliced mushrooms in 2 tablespoons vegetable stock, adding more stock if necessary. Transfer to rice bowl.\n",
      "\n",
      "9\tStir in bread crumbs, parsley, yeast, salt, thyme, basil, paprika and a pinch of black pepper, mixing well.\n",
      "\n",
      "0\t[('each', 'NOUN'), ('portion', 'NOUN'), ('1', 'NUM'), ('apple', 'NOUN')]\n",
      "1\t[('300°', 'NUM'), ('f', 'NOUN'), ('oven', 'NOUN')]\n",
      "2\t[('pierce', 'NOUN'), ('top', 'NOUN'), ('of', 'ADP'), ('apple', 'NOUN'), ('hold', 'VERB'), ('par', 'VERB'), ('knife', 'NOUN'), ('at', 'ADP'), ('a', 'DET'), ('45', 'NUM'), ('degree', 'NOUN'), ('angle', 'NOUN'), ('to', 'PRT'), ('stem', 'VERB'), ('rotate', 'NOUN'), ('knife', 'VERB'), ('around', 'ADV'), ('top', 'ADJ'), ('to', 'PRT'), ('produce', 'VERB'), ('small', 'ADJ'), ('cone-shaped', 'ADJ'), ('top', 'NOUN'), ('set', 'NOUN'), ('top', 'VERB'), ('aside', 'ADP'), ('using', 'VERB'), ('melon', 'NOUN'), ('baller', 'NOUN'), ('or', 'CONJ'), ('teaspoon', 'VERB'), ('remove', 'VERB'), ('core', 'NOUN'), ('from', 'ADP'), ('apples', 'ADJ'), ('be', 'VERB'), ('careful', 'ADJ'), ('not', 'ADV'), ('to', 'PRT'), ('pierce', 'VERB'), ('the', 'DET'), ('bottom', 'NOUN'), ('of', 'ADP'), ('apples', 'NOUN')]\n",
      "3\t[('in', 'ADP'), ('small', 'ADJ'), ('bowl', 'NOUN'), ('stir', 'NOUN'), ('together', 'ADV'), ('tahini', 'ADJ'), ('raisins', 'NOUN'), ('lemon', 'NOUN'), ('juice', 'NOUN'), ('grate', 'VERB'), ('lemon', 'ADJ'), ('peel', 'NOUN'), ('maple', 'NOUN'), ('syrup', 'NOUN'), ('cinnamon', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('pinch', 'NOUN'), ('of', 'ADP'), ('ground', 'NOUN'), ('cardamom', 'NOUN'), ('optional', 'NOUN'), ('fill', 'NOUN'), ('apple', 'NOUN'), ('cavitites', 'VERB'), ('almost', 'ADV'), ('to', 'PRT'), ('top', 'VERB'), ('with', 'ADP'), ('raisin', 'ADJ'), ('mixture', 'NOUN'), ('replace', 'NOUN'), ('apple', 'NOUN'), ('tops', 'NOUN'), ('set', 'NOUN'), ('apple', 'NOUN'), ('in', 'ADP'), ('bake', 'VERB'), ('tray', 'ADJ'), ('pour', 'NOUN'), ('orange', 'NOUN'), ('juice', 'NOUN'), ('over', 'ADP'), ('apple', 'NOUN'), ('and', 'CONJ'), ('bake', 'VERB'), ('for', 'ADP'), ('15', 'NUM'), ('minute', 'NOUN'), ('or', 'CONJ'), ('until', 'ADP'), ('apple', 'NOUN'), ('be', 'VERB'), ('soft', 'ADJ'), ('when', 'ADV'), ('pierce', 'VERB'), ('with', 'ADP'), ('toothpick', 'NOUN')]\n",
      "4\t[('saute', 'NOUN'), ('mushroom', 'NOUN'), ('in', 'ADP'), ('2', 'NUM'), ('tablespoon', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('stock', 'NOUN'), ('add', 'VERB'), ('more', 'ADJ'), ('stock', 'NOUN'), ('if', 'ADP'), ('necessary', 'ADJ'), ('or', 'CONJ'), ('in', 'ADP'), ('1', 'NUM'), ('tablespoon', 'NOUN'), ('oil', 'NOUN'), ('in', 'ADP'), ('large', 'ADJ'), ('pot', 'NOUN'), ('over', 'ADP'), ('medium', 'NOUN'), ('heat', 'NOUN'), ('for', 'ADP'), ('5', 'NUM'), ('minute', 'NOUN'), ('or', 'CONJ'), ('until', 'ADP'), ('they', 'PRON'), ('start', 'VERB'), ('to', 'PRT'), ('brown', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "import helpers as hp\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import wordnet as wn\n",
    "import preprocess \n",
    "from preprocess import pos_tag_db, lemmatize_db\n",
    "import csv\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from re import search\n",
    "# Get a list of available databases\n",
    "dbs = hp.getDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchout = [\"boil\", \"saute\", \"top\", 'fill', 'place', 'use', 'slice', 'steam', 'heat', 'serve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of ingredients\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import sys\n",
    "url = \"https://world.openfoodfacts.org/ingredients.json\"\n",
    "page = urlopen(url)\n",
    "html = page.read()\n",
    "soup = BeautifulSoup(html) \n",
    "u = soup.decode('utf-8')\n",
    "u = u.split('\"name\":')\n",
    "#creating a csv file with ingredients\n",
    "localFile = open('ingredients.csv', 'w')\n",
    "#creating a list of ingredients\n",
    "ingredients = []\n",
    "for line in u:\n",
    "    ingredients.append(line.split(',')[0])\n",
    "del ingredients[0]\n",
    "for ingredient in ingredients:\n",
    "    localFile.write(ingredient)\n",
    "localFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have 10000 ingredients in this vegetarian dataset\n",
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in ingredients:\n",
    "    #remove any string that contains digits\n",
    "    if any(map(str.isdigit, element)):\n",
    "        ingredients.remove(element)\n",
    "              \n",
    "   # if \"E1\" or \"E2\" or \"E3\" or \"E4\" or \"E9\" in element:\n",
    "    #    ingredients.remove(element)\n",
    "if \"ingredient\" in ingredients:\n",
    "    ingredients.remove(\"ingredient\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_str = str(ingredients)\n",
    "cleanString1 = re.sub('\"','', ingredients_str )\n",
    "cleanString = re.sub(\"'\",'', cleanString1)\n",
    "ingredients = cleanString\n",
    "ingredients = ingredients.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ingr in ingredients:\n",
    "    if len(ingr) < 4:\n",
    "        ingredients.remove(ingr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First database : 'VegetarianRecipes.exl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data structure of clean_db is a list of strings\n",
    "clean_db = hp.cleanFile(dbs[0])\n",
    "  \n",
    "#merging the cleaned sentenes \n",
    "vegetarian_recipes = []\n",
    "for sentence in clean_db:\n",
    "    vegetarian_recipes.append(sentence)\n",
    "#split into separate recipes\n",
    "split_vegetarian_recipes = str(vegetarian_recipes).split('EACH')\n",
    "del split_vegetarian_recipes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the recipes to a csv file\n",
    "with open('recipes_veg.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"EACH PORTION\", 'TEMPERATURE', \"METHODstr\", \"METHOD\", \"NOTE\", \"CONTAINS (NOUNS)\", \"INGREDIENTS\"])\n",
    "    #loop through each recipes \n",
    "    allmethod = []\n",
    "    for recipe in split_vegetarian_recipes:\n",
    "        #for each recipe create a list\n",
    "        portion = []\n",
    "        method = []\n",
    "        temperature = []\n",
    "        pan_size = []\n",
    "        note = []\n",
    "        contains = []\n",
    "        for sent in re.split(',|\\n', recipe):\n",
    "            if search('PORTION:', sent):\n",
    "                sent.replace('PORTION:','')\n",
    "                sent.replace('PAN','')\n",
    "                portion.append(sent.replace('PORTION:',''))\n",
    "                    \n",
    "            elif search('TEMPERATURE:', sent):\n",
    "                temperature.append(sent.replace('TEMPERATURE:',''))\n",
    "                \n",
    "            elif search('PAN SIZE:', sent):\n",
    "                pan_size.append(sent.replace('PAN SIZE:',''))\n",
    "                    \n",
    "            elif search('NOTE:', sent):\n",
    "                note.append(sent.replace('NOTE:',''))\n",
    "            else:\n",
    "                method.append(sent)\n",
    "        #merge method (as a list) into one single string\n",
    "        method_str = \"\"\n",
    "        for text in method:\n",
    "            method_str += str(text) + \" \"\n",
    "        savemethodstr = method_str\n",
    "        \n",
    "        for ingr in ingredients:\n",
    "            if ingr in savemethodstr:\n",
    "            #if search(ingr, savemethodstr):\n",
    "                savemethodstr.replace(ingr, \"INGREDIENT\")\n",
    "                contains.append(ingr)\n",
    "                \n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        method_str = tokenizer.tokenize(method_str)\n",
    "        #lemmatize and POS tag the method string\n",
    "        #PoS-Tag, lemmatize and format\n",
    "        postagged = pos_tag_db(method_str)\n",
    "        lemmatized = lemmatize_db(postagged, [\".\", \"X\"])\n",
    "        formatted = hp.formatFile(lemmatized)\n",
    "        method_tagged = formatted\n",
    "        onelist = []\n",
    "        for pair in method_tagged:\n",
    "            onelist.extend(pair)\n",
    "       # for (word, tag) in onelist:\n",
    "        #    if (tag == 'NOUN'):\n",
    "         #       contains.append(word)\n",
    "        #from contains we can filter for features like ingredients and tools\n",
    "        ingre = []\n",
    "        #for contain in contains:\n",
    "         #   if search(contain, str(ingredients)) and (len(contain) > 1) and contain not in watchout:\n",
    "          #      ingre.append(contain)\n",
    "        #write row for each recipe\n",
    "        #the ingredients are turned into a set, so there is no repetition of ingredients.\n",
    "        writer.writerow([portion, temperature, savemethodstr ,onelist, note, contains, set(ingre)])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second database: 'data/EthnicRecipes.exl' Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where's the method??\n",
    "\n",
    "clean_db = hp.cleanFile(dbs[1])\n",
    "#merging the cleaned sentenes \n",
    "ethnic_recipes = []\n",
    "for sentence in clean_db:\n",
    "    ethnic_recipes.append(sentence)\n",
    "#split the recipes into lists\n",
    "split_ethnic_recipes = str(ethnic_recipes).split('COOK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third database: data/ArmedForcesRecipes.exl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_db = hp.cleanFile(dbs[2])\n",
    "armedforces_recipes = []\n",
    "for sentence in clean_db:\n",
    "    armedforces_recipes.append(sentence)\n",
    "#split the recipes into lists\n",
    "split_armedforces_recipes = str(armedforces_recipes).split('EACH')\n",
    "del split_armedforces_recipes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the recipes to a csv file\n",
    "with open('recipes_armed.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"EACH PORTION\", 'TEMPERATURE',  \"METHODstr\",\"METHOD\", \"NOTE\", \"CONTAINS (NOUNS)\", \"INGREDIENTS\"])\n",
    "    #loop through each recipes \n",
    "    allmethod = []\n",
    "    for recipe in split_armedforces_recipes:\n",
    "        #for each recipe create a list\n",
    "        portion = []\n",
    "        method = []\n",
    "        temperature = []\n",
    "        pan_size = []\n",
    "        note = []\n",
    "        contains = []\n",
    "        for sent in re.split(',|\\n', recipe):\n",
    "            if search('PORTION:', sent):\n",
    "                sent.replace('PORTION:','')\n",
    "                sent.replace('PAN','')\n",
    "                portion.append(sent.replace('PORTION:',''))\n",
    "                    \n",
    "            elif search('TEMPERATURE:', sent):\n",
    "                temperature.append(sent.replace('TEMPERATURE:',''))\n",
    "                \n",
    "            elif search('PAN SIZE:', sent):\n",
    "                pan_size.append(sent.replace('PAN SIZE:',''))\n",
    "                    \n",
    "            elif search('NOTE:', sent):\n",
    "                note.append(sent.replace('NOTE:',''))\n",
    "            else:\n",
    "                method.append(sent)\n",
    "        #merge method (as a list) into one single string\n",
    "        method_str = \"\"\n",
    "        for text in method:\n",
    "            method_str += str(text) + \" \"\n",
    "        savemethodstr = method_str\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        method_str = tokenizer.tokenize(method_str)\n",
    "        #lemmatize and POS tag the method string\n",
    "        #PoS-Tag, lemmatize and format\n",
    "        postagged = pos_tag_db(method_str)\n",
    "        lemmatized = lemmatize_db(postagged, [\".\", \"X\"])\n",
    "        formatted = hp.formatFile(lemmatized)\n",
    "        method_tagged = formatted\n",
    "        onelist = []\n",
    "        for pair in method_tagged:\n",
    "            onelist.extend(pair)\n",
    "        for (word, tag) in onelist:\n",
    "            if (tag == 'NOUN'):\n",
    "                contains.append(word)\n",
    "        #from contains we can filter for features like ingredients and tools\n",
    "        ingre = []\n",
    "        for contain in contains:\n",
    "            if search(contain, str(ingredients)) and (len(contain) > 1) and contain not in watchout:\n",
    "                ingre.append(contain)\n",
    "        #write row for each recipe\n",
    "        #the ingredients are turned into a set, so there is no repetition of ingredients.\n",
    "        writer.writerow([portion, temperature, savemethodstr, onelist, note, contains, set(ingre)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth database: 'data/CommonRecipes.exl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_db = hp.cleanFile(dbs[3])\n",
    "common_recipes = []\n",
    "for sentence in clean_db:\n",
    "    common_recipes.append(sentence)\n",
    "#split the recipes into lists\n",
    "split_common_recipes = str(common_recipes).split('EACH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the recipes to a csv file\n",
    "with open('recipes_common.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"EACH PORTION\", 'TEMPERATURE', \"METHODstr\",\"METHOD\", \"NOTE\", \"CONTAINS (NOUNS)\", \"INGREDIENTS\"])\n",
    "    #loop through each recipes \n",
    "    allmethod = []\n",
    "    for recipe in split_common_recipes:\n",
    "        #for each recipe create a list\n",
    "        portion = []\n",
    "        method = []\n",
    "        temperature = []\n",
    "        pan_size = []\n",
    "        note = []\n",
    "        contains = []\n",
    "        for sent in re.split(',|\\n', recipe):\n",
    "            if search('PORTION:', sent):\n",
    "                sent.replace('PORTION:','')\n",
    "                sent.replace('PAN','')\n",
    "                portion.append(sent.replace('PORTION:',''))\n",
    "                    \n",
    "            elif search('TEMPERATURE:', sent):\n",
    "                temperature.append(sent.replace('TEMPERATURE:',''))\n",
    "                \n",
    "            elif search('PAN SIZE:', sent):\n",
    "                pan_size.append(sent.replace('PAN SIZE:',''))\n",
    "                    \n",
    "            elif search('NOTE:', sent):\n",
    "                note.append(sent.replace('NOTE:',''))\n",
    "            else:\n",
    "                method.append(sent)\n",
    "        #merge method (as a list) into one single string\n",
    "        method_str = \"\"\n",
    "        for text in method:\n",
    "            method_str += str(text) + \" \"\n",
    "        savemethodstr = method_str\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        method_str = tokenizer.tokenize(method_str)\n",
    "        #lemmatize and POS tag the method string\n",
    "        #PoS-Tag, lemmatize and format\n",
    "        postagged = pos_tag_db(method_str)\n",
    "        lemmatized = lemmatize_db(postagged, [\".\", \"X\"])\n",
    "        formatted = hp.formatFile(lemmatized)\n",
    "        method_tagged = formatted\n",
    "        onelist = []\n",
    "        for pair in method_tagged:\n",
    "            onelist.extend(pair)\n",
    "        for (word, tag) in onelist:\n",
    "            if (tag == 'NOUN'):\n",
    "                contains.append(word)\n",
    "        #from contains we can filter for features like ingredients and tools\n",
    "        ingre = []\n",
    "        for contain in contains:\n",
    "            if search(contain, str(ingredients)) and (len(contain) > 1) and contain not in watchout:\n",
    "                ingre.append(contain)\n",
    "        #write row for each recipe\n",
    "        #the ingredients are turned into a set, so there is no repetition of ingredients.\n",
    "        writer.writerow([portion, temperature, savemethodstr, onelist, note, contains, set(ingre)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
